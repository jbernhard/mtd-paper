\documentclass[aps,prc,reprint,amsmath]{revtex4-1}

\usepackage[bookmarksopen=true]{hyperref}
\usepackage{graphicx}
\graphicspath{{fig/}}

\usepackage{color}
\newcommand{\todo}[1]{\textcolor{red}{#1}}

\newcommand{\widefig}[3][t]{
  \begin{figure*}[#1]
    \includegraphics{#2}
    \caption{\label{fig:#2}#3}
  \end{figure*}
}

\newcommand{\placeholderfig}[3][t]{
  \begin{figure}[#1]
    \centering
    \framebox{\parbox[c][.5\columnwidth]{\columnwidth}{
      placeholder
    }}
    \caption{\label{fig:#2}#3}
  \end{figure}
}

\newcommand{\avg}[1]{\langle #1 \rangle}
\newcommand{\nch}{N_\text{ch}}
\newcommand{\vnk}[2]{v_#1\{#2\}}


\begin{document}

\title{Extracting QGP properties via systematic model-to-data comparison}

\author{Jonah E.\ Bernhard}
\author{Steffen A.\ Bass}
\author{Christopher E.\ Coleman-Smith}
\author{Robert L.\ Wolpert}
\affiliation{Duke University}

\author{Snehalata Huzurbazar}
\affiliation{University of Wyoming}

\author{Peter Marcy}
\affiliation{Los Alamos National Lab}


\date{\today}

\begin{abstract}
  hello
\end{abstract}

\maketitle


\section{Introduction}

Relativistic heavy-ion collisions produce a hot, dense phase of strongly-interacting matter commonly known as the quark-gluon plasma (QGP) which rapidly expands and freezes into discrete particles \cite{}.
Since the QGP is not directly observable---only final-state hadrons are detected---present research seeks to quantify the fundamental properties of the QGP, such as its transport coefficients and the nature of the initial state, through comparisons of experimental measurements to computational model calculations.

Computational models must take a set of input parameters including the physical properties of interest, simulate the full time-evolution of heavy-ion collisions, and produce output analogous to experimental measurements.
The true values of the physical properties are extracted by calibrating the input parameters so that the model output optimally reproduces experimental data.
This generic recipe is called ``model-to-data comparison''.

Notably, previous studies have used viscous relativistic fluid dynamics to place constraints on the QGP shear viscosity to entropy density ratio $\eta/s$ by comparing anisotropic flow coefficients $v_n$ between model and experiment \cite{}.
$\eta/s$ cannot be calculated directly from QCD, and while there is a conjectured lower bound $\eta/s~\geq~1/4\pi~\simeq~0.08$ from AdS/CFT holography \cite{}, model-to-data comparison is the most attractive option for determining the precise value.
These studies generally proceed by calculating fluid dynamical $v_n$ at several values of $\eta/s$, then choosing the value which most closely matches experimental $v_n$.
A variety of complimentary results have constrained $\eta/s$ to an approximate range of 0.08--0.20 \cite{}.

However, $\eta/s$ is not the only model input parameter:
many other parameters remain unconstrained, e.g.~the hydrodynamic thermalization time $\tau_0$, equation of state, and initial conditions; and models often have non-physical nuisance parameters that nonetheless should be tuned to optimal values.
$v_n$ is not the only output:
basic observables like the charged-particle multiplicity and transverse-momentum distributions must also be simulated accurately.
Input parameters are in general correlated among each other and each affects multiple outputs, so they cannot be constrained independently.
Due to these practical limitations, most studies to date have focused on a single input parameter, fixed secondary parameters to default values, and calibrated to a minimal set of observables \cite{}.
This leads to nebulous results with poorly-defined constraints, non-quantitative uncertainties, and no treatment of correlations.

\todo{
  Cite R.~Soltz \emph{et.~al.}\ somehow \cite{Soltz:2012rk}.
  They do a more systematic study but do not use an emulator.
}

Algorithms such as Markov chain Monte Carlo (MCMC) can rigorously explore this type of complex multivariate input-output parameter space, but MCMC requires a very large number of model evaluations: $\mathcal O(10^6)$ or more.
Heavy-ion collision models may run for several hours, so a direct MCMC approach is intractable.
The situation is exacerbated with a full event-by-event model, since many thousands of events must be calculated \emph{at each point in parameter space} to capture event-by-event fluctuations.

These limitations may be overcome through a modern Bayesian method for analyzing computationally expensive models \cite{OHagan:2006ba,Higdon:2008cmc,Higdon:2014tva}.
A set of salient model parameters is chosen for calibration---the set should include any fundamental physical properties of interest---and the model is evaluated at a relatively small $\mathcal O(10^2)$ number of points in parameter space.
Those points are then interpolated with a Gaussian process emulator \cite{Rasmussen:2006gp} to provide a continuous picture of parameter space.
The emulator acts as a fast surrogate to the full model:
it predicts model output at arbitrary points in parameter space with negligible computational cost.
Parameters are calibrated by sampling the emulator with standard MCMC techniques.

Emulators have been successfully used to study a wide range of physical systems, including galaxy formation \cite{Gomez:2012ak} and heavy-ion collisions \cite{Novak:2013bqa}.
Reference \cite{Novak:2013bqa} calibrated a hydrodynamic model to identified particle spectra from the Relativistic Heavy Ion Collider (RHIC) and extracted constraints on $\eta/s$ and several initial state parameters.
However, this study used an event-averaged initial condition model, limiting its ability to investigate event-by-event fluctuations.

In this work, we apply Bayesian methodology to a full event-by-event heavy-ion collision model.
We calibrate to anisotropic flow data from the Large Hadron Collider (LHC) and constrain the shear viscosity $\eta/s$ along with other hydrodynamic and initial condition parameters.
The analysis framework handles arbitrary numbers of inputs and outputs, systematically calculates quantitative constraints on all inputs simultaneously, and quickly evaluates the efficacy of physical models.


\section{Model}

\cite{Bass:2000ib, Nonaka:2006yn, Song:2010mg}
\cite{Miller:2007ri}
\cite{Drescher:2006pi}
\cite{Song:2007ux}
\cite{Cooper:1974mv}
\cite{Qiu:2013wca}
\cite{Bass:1998ca, Bleicher:1999xi}
\cite{Shen:2014vra}

\widefig{prior_draws_glb}{
  Prior model calculations using Glauber initial conditions.
  From left to right:
  average charged-particle multiplicity $\avg\nch$,
  elliptic flow two-particle cumulant $\vnk 2 2$,
  and triangular flow two-particle cumulant $\vnk 3 2$.
  Each plot has 254 lines corresponding to the 254 design points.
  Data points are experimental measurements from ALICE \cite{Abelev:2014mda}.
}

\widefig{prior_draws_kln}{
  Same as FIG.~\ref{fig:prior_draws_glb} for KLN initial conditions.
}


\section{Emulator}

\cite{Rasmussen:2006gp}
\cite{OHagan:2006ba, Higdon:2008cmc, Higdon:2014tva}

\placeholderfig{gp}{
  Conditioning a Gaussian process.
}

\placeholderfig{design}{
  Latin-hypercube experiment design.
}

\placeholderfig{pca}{
  Dimensionality reduction via principal component analysis.
}

\widefig{validation_glb}{
  Validation of the Gaussian process emulator for the Glauber model.
  Each plot shows emulator predictions against explicit calculations for the 64 validation design points and centrality bins 0--5\%, 20--25\%, and 40-45\%.
  The $x$-value of each data point is the emulator prediction with 95\% error bars; the $y$-value is the explicit calculation.
  The diagonal grey line represents $y = x$.
}


\section{Calibration}

\cite{Abelev:2014mda}
\cite{Shen:2011zc, Heinz:2011kt}

\widefig{calibration_posterior_glb}{
  Posterior marginal and joint distributions of the calibration parameters for the Glauber model.
  On the diagonal are histograms of MCMC samples for the respective parameters,
  on the lower triangle are two-dimensional histograms of MCMC samples showing the correlation between pairs of parameters,
  and on the upper triangle are approximate contours for 68\%, 95\%, and 99\% confidence intervals along with a dot indicating the median.
}

\widefig{calibration_posterior_kln}{
  Same as FIG.~\ref{fig:calibration_posterior_glb} for the KLN model.
}

\placeholderfig{posterior_comparison}{
  Comparison of posterior distributions from the Glauber and KLN models (boxplots or similar).
  Also comparison to prior guesses from OSU.
}

\begin{table}[b]
  \caption{
    \label{tab:posterior}
    Quantitative summary of posterior distributions.
  }
  \begin{ruledtabular}
  \begin{tabular}{llll}
    Parameter & Mean & Median & Confidence intervals \\
    $\eta/s$ & & & \\
  \end{tabular}
  \end{ruledtabular}
\end{table}

\placeholderfig{chi_squared}{
  Goodness of fit comparison.
}

\widefig{posterior_draws_glb}{
  Random realizations of the calibrated posterior for the Glauber model.
  Similar to FIG.~\ref{fig:prior_draws_glb},
  except the lines are posterior emulator predictions instead of explicit prior calculations.
  The red line is the maximum a posteriori point of the MCMC chain.
}

\widefig{posterior_draws_kln}{
  Same as FIG.~\ref{fig:posterior_draws_glb} for the KLN model.
}



\section{Conclusion}



\appendix


\section{Emulator training}

\widefig{training_posterior_glb}{
  Posterior distributions of the principal component Gaussian process hyperparameters for the Glauber model.
  The notation $\ell\;x$ means the squared-exponential correlation length for parameter $x$.
}

\widefig{training_posterior_kln}{
  Same as FIG.~\ref{fig:training_posterior_glb} for the KLN model.
}



\bibliography{mtd}


\end{document}

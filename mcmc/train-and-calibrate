#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import pickle

import numpy as np
import mtd


class ModelData:
    """
    Read data as created by DataPreprocessor in ../data/model/preprocess and
    handle basic array manipulations.

    """
    def __init__(self, ic, datadir='../data/model'):
        with open('{}/{}.pkl'.format(datadir, ic), 'rb') as f:
            self.__dict__.update(pickle.load(f))

        # cache quantities for transforming mult
        sqrt_mult = np.sqrt(self.mult)
        self._sqrt_mult_mean = sqrt_mult.mean(axis=0)
        self._sqrt_mult_std = sqrt_mult.std(axis=0)
        self._v2_std = self.v2.std(axis=0)

    @property
    def full_output(self):
        """
        Full matrix of training data (mult, v2, v3).

        """
        return np.hstack((self.transform_mult(), self.v2, self.v3))

    def unpack_full_output(self, y):
        """
        Separate a full matrix into (mult, v2, v3).

        """
        mult, v2, v3 = np.hsplit(y, 3)
        mult = self.inv_transform_mult(mult)
        return mult, v2, v3

    @property
    def ndim(self):
        """
        Number of input dimensions.

        """
        return self.design.shape[1]

    def transform_mult(self, mult=None):
        """
        Transform multiplicity data before PCA:

            - Take square root (makes the distribution more normal).
            - Center (subtract mean).
            - Scale to same variance as v2.

        """
        if mult is None:
            mult = self.mult

        mult = np.sqrt(mult)
        mult -= self._sqrt_mult_mean
        mult *= self._v2_std / self._sqrt_mult_std

        return mult

    def inv_transform_mult(self, mult):
        """
        Apply the inverse multiplicity transformation.

        """
        mult = mult * self._sqrt_mult_std / self._v2_std
        mult += self._sqrt_mult_mean
        mult **= 2.

        return mult


def main():
    print('loading data')
    ic = 'glb'
    md = ModelData(ic)
    ndim = md.ndim

    # GP kernel and conjugate prior for hyperparameters
    kernel = (
        1. *
        mtd.kernels.ExpSquaredKernel(np.full(ndim, .5), ndim=ndim) +
        mtd.kernels.WhiteKernel(1e-8, ndim=ndim)
    )
    training_prior = (
        mtd.priors.VariancePrior() +
        ndim * mtd.priors.LengthScalePrior() +
        mtd.priors.NoisePrior()
    )

    print('starting GPs')
    mgp = mtd.MultiGP(md.design, md.full_output, kernel, npc=.99)
    npc = len(mgp)
    results = {}
    print('using {} PCs'.format(npc))

    mgp.train(training_prior, 200, 200, verbose=True)
    results['training_chains'] = np.array([
        mgp.get_training_sampler_attr(n, 'flatchain') for n in range(npc)
    ])

    with open('../data/exp/alice.pkl', 'rb') as f:
        expdata = pickle.load(f)

    yexp = np.concatenate((
        md.transform_mult(expdata['mult']['mean']),
        expdata['v2']['mean'],
        expdata['v3']['mean']
    ))
    cal_prior = mtd.priors.FlatPrior() * ndim

    mgp.calibrate(yexp, .03, cal_prior, 200, 200, verbose=True)
    results['calibration_chain'] = mgp.get_calibration_chain(flat=True)

    print('predicting validation design')
    mdv = ModelData(ic + '-validation')
    results['validation_predictions'] = md.unpack_full_output(
        mgp.predict(mdv.design)
    )

    print('saving results')
    with open('{}.pkl'.format(ic), 'wb') as f:
        pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)


if __name__ == "__main__":
    main()

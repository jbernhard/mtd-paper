#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import pickle

import numpy as np
import mtd


class DataHandler:
    """
    Read data as created by preprocessor scripts and handle basic array
    manipulations.

    """
    def __init__(self, ic, exp, datadir='../data'):
        with open('{}/model/{}.pkl'.format(datadir, ic), 'rb') as f:
            self.__dict__.update(pickle.load(f))

        with open('{}/exp/{}.pkl'.format(datadir, exp), 'rb') as f:
            self._exp = pickle.load(f)

    @property
    def ndim(self):
        """
        Number of input dimensions.

        """
        return self.design.shape[1]

    @property
    def nfeatures(self):
        """
        Number of outputs.

        """
        return sum(i.shape[1] for i in (self.mult, self.v2, self.v3))

    @property
    def exp_data(self):
        """
        Experimental data (mult, v2, v3).

        """
        mult, v2, v3 = (self._exp[i]['mean'] for i in ('mult', 'v2', 'v3'))
        return self._concat(mult, v2, v3)

    @property
    def cal_data(self):
        """
        Calibration data.

        """
        return np.ones(self.nfeatures)

    @property
    def training_data(self):
        """
        Full matrix of training data (mult, v2, v3).

        Preprocessing:
            - Square root of mult.
            - Scale by experimental data.

        """
        return self._concat(self.mult, self.v2, self.v3) / self.exp_data

    @staticmethod
    def _concat(mult, v2, v3):
        """
        Take square root of mult and concatenate rows.

        """
        return np.hstack((np.sqrt(mult), v2, v3))

    def unpack(self, y, std=None):
        """
        Separate a full matrix into a dict of (mult, v2, v3) and invert
        preprocessing steps from self.training_data.

        """
        y = y * self.exp_data
        sqrt_mult, v2, v3 = np.hsplit(y, 3)
        mult = np.square(sqrt_mult)

        if std is None:
            return dict(mult=mult, v2=v2, v3=v3)
        else:
            std = std * self.exp_data
            sqrt_mult_std, v2_std, v3_std = np.hsplit(std, 3)
            mult_std = 2. * sqrt_mult_std * sqrt_mult
            return dict(
                mult={'mean': mult, 'std': mult_std},
                v2={'mean': v2, 'std': v2_std},
                v3={'mean': v3, 'std': v3_std}
            )


def main():
    print('loading data')
    ic = 'glb'
    exp = 'alice'
    data = DataHandler(ic, exp)
    ndim = data.ndim

    # GP kernel and conjugate prior for hyperparameters
    kernel = (
        1. *
        mtd.kernels.ExpSquaredKernel(np.full(ndim, .5), ndim=ndim) +
        mtd.kernels.WhiteKernel(1e-8, ndim=ndim)
    )
    training_prior = (
        mtd.priors.VariancePrior() +
        ndim * mtd.priors.LengthScalePrior(b=0.3) +
        mtd.priors.NoisePrior()
    )

    print('starting GPs')
    mgp = mtd.MultiGP(data.design, data.training_data, kernel, npc=.99)
    npc = len(mgp)
    results = {}
    print('using {} PCs'.format(npc))

    mgp.train(training_prior,
              nwalkers=50, nsteps=300, nburnsteps=100,
              verbose=True)
    results['training_samplers'] = mgp.training_samplers

    # cal_prior = mtd.priors.FlatPrior() * ndim
    mgp.calibrate(data.cal_data, yerr=.10,
                  nwalkers=100, nsteps=500, nburnsteps=200,
                  verbose=True)
    results['cal_chain'] = mgp.cal_flatchain
    results['cal_samples'] = data.unpack(mgp.cal_samples)

    print('predicting validation design')
    vdata = DataHandler(ic + '-validation', exp)
    pred_mean, pred_var = mgp.predict(vdata.design, mean_only=False)
    pred_std = np.sqrt(pred_var, out=pred_var)
    results['validation'] = data.unpack(pred_mean, pred_std)

    print('saving results')
    with open('{}.pkl'.format(ic), 'wb') as f:
        pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import pickle
import sys

import numpy as np
import mtd


class DataHandler:
    """
    Read data as created by preprocessor scripts and handle basic array
    manipulations.

    """
    def __init__(self, ic, exp, weights=np.ones(3), datadir='../data'):
        with open('{}/model/{}.pkl'.format(datadir, ic), 'rb') as f:
            self.__dict__.update(pickle.load(f))

        with open('{}/exp/{}.pkl'.format(datadir, exp), 'rb') as f:
            self._exp = pickle.load(f)

        obs = self.mult, self.v2, self.v3
        self._nobs = len(obs)
        self._ncent = obs[0].shape[1]
        assert all(i.shape[1] == self._ncent for i in obs)
        assert all(self._exp[i]['mean'].size == self._ncent
                   for i in ('mult', 'v2', 'v3'))

        weights = np.asarray(weights, dtype=float)
        assert weights.size == self._nobs
        self._weights = weights.repeat(self._ncent)

    @property
    def ndim(self):
        """
        Number of input dimensions.

        """
        return self.design.shape[1]

    @property
    def nfeatures(self):
        """
        Number of outputs.

        """
        return self._nobs * self._ncent

    @property
    def exp_data(self):
        """
        Experimental data (mult, v2, v3).

        """
        mult, v2, v3 = (self._exp[i]['mean'] for i in ('mult', 'v2', 'v3'))
        return self._concat(mult, v2, v3)

    @property
    def cal_data(self):
        """
        Calibration data.

        """
        return self._weights

    @property
    def training_data(self):
        """
        Full matrix of training data (mult, v2, v3).

        Preprocessing:
            - Square root of mult.
            - Apply weights.
            - Scale by experimental data.

        """
        data = self._concat(self.mult, self.v2, self.v3)
        data *= self._weights / self.exp_data
        return data

    @staticmethod
    def _concat(mult, v2, v3):
        """
        Take square root of mult and concatenate rows.

        """
        return np.hstack((np.sqrt(mult), v2, v3))

    def unpack(self, y, std=None):
        """
        Separate a full matrix into a dict of (mult, v2, v3) and invert
        preprocessing steps from self.training_data.

        """
        y = y * self.exp_data / self._weights
        sqrt_mult, v2, v3 = np.hsplit(y, 3)
        mult = np.square(sqrt_mult)

        if std is None:
            return dict(mult=mult, v2=v2, v3=v3)
        else:
            std = std * self.exp_data / self._weights
            sqrt_mult_std, v2_std, v3_std = np.hsplit(std, 3)
            mult_std = 2. * sqrt_mult_std * sqrt_mult
            return dict(
                mult={'mean': mult, 'std': mult_std},
                v2={'mean': v2, 'std': v2_std},
                v3={'mean': v3, 'std': v3_std}
            )


def main():
    print('loading data')
    try:
        ic = sys.argv[1]
    except IndexError:
        ic = 'glb'

    exp = 'alice'
    data = DataHandler(ic, exp, weights=(3, 2, 1))
    ndim = data.ndim

    # GP kernel and conjugate prior for hyperparameters
    kernel = (
        1. *
        mtd.kernels.ExpSquaredKernel(np.full(ndim, .5), ndim=ndim) +
        mtd.kernels.WhiteKernel(1e-8, ndim=ndim)
    )
    training_prior = (
        mtd.priors.VariancePrior() +
        ndim * mtd.priors.LengthScalePrior(b=0.3) +
        mtd.priors.NoisePrior()
    )

    print('starting GPs')
    mgp = mtd.MultiGP(data.design, data.training_data, kernel, npc=.995)
    npc = len(mgp)
    results = {}
    print('using {} PCs'.format(npc))

    mgp.train(training_prior,
              nwalkers=100, nsteps=300, nburnsteps=100,
              verbose=True)
    results['training_samplers'] = mgp.training_samplers

    # cal_prior = mtd.priors.FlatPrior() * ndim
    mgp.calibrate(data.cal_data, yerr=.10,
                  nwalkers=200, nsteps=1000, nburnsteps=300,
                  verbose=True)
    results['cal_chain'] = mgp.cal_flatchain
    results['cal_samples'] = data.unpack(mgp.cal_samples)
    results['cal_logprob'] = mgp.cal_sampler.flatlnprobability

    if ic == 'glb':
        print('predicting validation design')
        with open('../data/model/{}-validation.pkl'.format(ic), 'rb') as f:
            vdesign = pickle.load(f)['design']
        pred_mean, pred_var = mgp.predict(vdesign, mean_only=False)
        pred_std = np.sqrt(pred_var, out=pred_var)
        results['validation'] = data.unpack(pred_mean, pred_std)

    print('saving results')
    with open('{}.pkl'.format(ic), 'wb') as f:
        pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)


if __name__ == "__main__":
    main()
